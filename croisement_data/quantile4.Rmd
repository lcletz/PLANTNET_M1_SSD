---
title: "quantile4"
author: "AIGOIN Emilie"
date: "2025-05-22"
output: html_document
---

```{r}

# Chargement des bibliothèques nécessaires
library(jsonlite)
library(dplyr)

```

Calibration

```{r}

# Récupération des scores de non conformité

# Charger les données expertes avec scores
load_expert_scores <- function(chemin) {
  expert_file <- file.path(chemin, "expert_processed_scores.json")
  data <- fromJSON(expert_file, simplifyDataFrame = FALSE)
  cat("Scores experts chargés:", length(data), "observations\n")
  return(data)
}

# Charger les données expertes brutes
load_expert_raw <- function(chemin) {
  expert_file <- file.path(chemin, "expert_processed.json")
  data <- fromJSON(expert_file, simplifyDataFrame = FALSE)
  cat("Données brutes expertes chargées:", length(data), "observations\n")
  return(data)
}

# Charger les données non-expertes avec scores
load_nonexpert_scores <- function(chemin) {
  nonexp_folder <- file.path(chemin, "data_n_exp")
  nonexp_data <- list()
  
  # Charger tous les fichiers scores_nonexp_XX.json
  for (i in 1:34) {
    file_num <- sprintf("%02d", i)
    file_path <- file.path(nonexp_folder, paste0("scores_nonexp_", file_num, ".json"))
    
    temp_data <- fromJSON(file_path, simplifyDataFrame = FALSE)
    nonexp_data <- c(nonexp_data, temp_data)
    cat("Chargé:", basename(file_path), "- Observations:", length(temp_data), "\n")
  }
  
  cat("Total observations non-expertes:", length(nonexp_data), "\n")
  return(nonexp_data)
}

```

```{r}

# Diviser les experts en deux moitiés aléatoirement

split_expert_data <- function(expert_scores, expert_raw) {
  expert_ids <- names(expert_scores)
  n_experts <- length(expert_ids)
  
  # Mélanger aléatoirement
  set.seed(42)                        # Pour la reproductibilité
  shuffled_ids <- sample(expert_ids)
  
  # Diviser en deux moitiés
  mid_point <- floor(n_experts / 2)
  half1_ids <- shuffled_ids[1:mid_point]
  half2_ids <- shuffled_ids[(mid_point + 1):n_experts]
  
  # Diviser les scores
  half1_scores <- expert_scores[half1_ids]
  half2_scores <- expert_scores[half2_ids]
  
  # Diviser les données brutes
  half1_raw <- expert_raw[half1_ids]
  half2_raw <- expert_raw[half2_ids]
  
  cat("Experts moitié 1:", length(half1_scores), "observations\n")
  cat("Experts moitié 2:", length(half2_scores), "observations\n")
  
  return(list(
    half1_scores = half1_scores,
    half2_scores = half2_scores,
    half1_raw = half1_raw,
    half2_raw = half2_raw
  ))
}

```

```{r}

# Fonction pour extraire les scores d'un type donné

extract_scores <- function(score_data, score_type) {
  scores <- sapply(score_data, function(obs) {
    if (score_type == "one_minus_prob") {
      return(obs$one_minus_prob[1])
    } else 
      if (score_type == "sum_until_correct") {
      return(obs$sum_until_correct[1])
    }
  })
  return(as.numeric(scores))
}

```

```{r}

# Fonction pour calculer le quantile conforme

calculate_conformal_quantile <- function(calibration_scores, alpha = 0.05) {
  n_cal <- length(calibration_scores)
  
  # Quantile conforme : (n+1)(1-alpha)/n quantile empirique
  q_level <- (n_cal + 1) * (1 - alpha) / n_cal
  q_level <- min(q_level, 1)  # S'assurer qu'il est <= 1
  
  quantile_value <- quantile(calibration_scores, q_level, type = 1)
  
  return(list(
    quantile = as.numeric(quantile_value),
    q_level = q_level,
    n_calibration = n_cal
  ))
}

```

```{r}

# Fonction pour créer l'ensemble de prédiction

create_prediction_set <- function(raw_data_obs, threshold, score_type) {
  # raw_data_obs est une liste des prédictions pour une observation
  
  prediction_set <- c()
  
  if (score_type == "one_minus_prob") {
    # Pour le score 1-prob : inclure tous les labels avec score <= seuil
    for (pred in raw_data_obs) {
      score <- 1 - pred$proba
      if (score <= threshold) {
        prediction_set <- c(prediction_set, pred$name)
      }
    }
  } else if (score_type == "sum_until_correct") {
    # Pour APS : trier par probabilité décroissante et calculer scores cumulatifs
    sorted_preds <- raw_data_obs[order(sapply(raw_data_obs, function(x) -x$proba))]
    
    cumulative_prob <- 0
    for (i in 1:length(sorted_preds)) {
      pred <- sorted_preds[[i]]
      
      # Le score APS pour ce label est la somme cumulative AVANT ce label
      score_aps <- cumulative_prob
      
      if (score_aps <= threshold) {
        prediction_set <- c(prediction_set, pred$name)
      }
      
      # Ajouter cette probabilité à la somme cumulative pour le prochain
      cumulative_prob <- cumulative_prob + pred$proba
    }
  }
  
  return(prediction_set)
}

```

```{r}

# Fonction pour calculer le taux de couverture

calculate_coverage <- function(test_raw_data, quantile_threshold, score_type) {
  n_test <- length(test_raw_data)
  covered <- 0
  prediction_set_sizes <- c()
  
  for (obs_id in names(test_raw_data)) {
    obs_data <- test_raw_data[[obs_id]]
    
    # Créer l'ensemble de prédiction SANS utiliser le vrai label
    pred_set <- create_prediction_set(obs_data, quantile_threshold, score_type)
    prediction_set_sizes <- c(prediction_set_sizes, length(pred_set))
    
    # MAINTENANT on vérifie si la vraie étiquette est dans l'ensemble
    true_labels <- sapply(obs_data, function(x) if(x$correct == 1) x$name else NA)
    true_label <- true_labels[!is.na(true_labels)][1]
    
    if (true_label %in% pred_set) {
      covered <- covered + 1
    }
  }
  
  coverage_rate <- covered / n_test
  avg_size <- mean(prediction_set_sizes)
  median_size <- median(prediction_set_sizes)
  
  return(list(
    coverage_rate = coverage_rate,
    avg_size = avg_size,
    median_size = median_size,
    n_test = n_test,
    n_covered = covered
  ))
}

```

```{r}

# Charger toutes les données
chemin <- "."

# Charger les données
expert_scores <- load_expert_scores(chemin)
expert_raw <- load_expert_raw(chemin)
nonexpert_scores <- load_nonexpert_scores(chemin)

# Diviser les experts et non-experts
expert_split <- split_expert_data(expert_scores, expert_raw)

```

```{r}

# Séparation pour les groupes

# Groupe 1: Score 1-prob, calibration sur non-experts, test sur moitié2 des EXPERTS
groupe1_cal <- extract_scores(nonexpert_scores, "one_minus_prob")
groupe1_test <- expert_split$half2_raw

# Groupe 2: Score 1-prob, calibration sur moitié1 des experts, test sur moitié2 des EXPERTS  
groupe2_cal <- extract_scores(expert_split$half1_scores, "one_minus_prob")
groupe2_test <- expert_split$half2_raw

# Groupe 3: Score APS, calibration sur non-experts, test sur moitié2 des EXPERTS
groupe3_cal <- extract_scores(nonexpert_scores, "sum_until_correct")
groupe3_test <- expert_split$half2_raw

# Groupe 4: Score APS, calibration sur moitié1 experts, test sur moitié2 des EXPERTS
groupe4_cal <- extract_scores(expert_split$half1_scores, "sum_until_correct")
groupe4_test <- expert_split$half2_raw

cat("Groupe 1 - Calibration:", length(groupe1_cal), "observations\n")
cat("Groupe 2 - Calibration:", length(groupe2_cal), "observations\n") 
cat("Groupe 3 - Calibration:", length(groupe3_cal), "observations\n")
cat("Groupe 4 - Calibration:", length(groupe4_cal), "observations\n")

```

```{r}

# Calcul du quantile pour chaque groupe
alpha <- 0.05  # Niveau de confiance 95%

quantile_g1 <- calculate_conformal_quantile(groupe1_cal, alpha)
quantile_g2 <- calculate_conformal_quantile(groupe2_cal, alpha)
quantile_g3 <- calculate_conformal_quantile(groupe3_cal, alpha)
quantile_g4 <- calculate_conformal_quantile(groupe4_cal, alpha)

cat("Quantiles calculés:\n")
cat("Groupe 1 (1-prob, non-experts):", quantile_g1$quantile, "\n")
cat("Groupe 2 (1-prob, experts-half1):", quantile_g2$quantile, "\n")
cat("Groupe 3 (APS, non-experts):", quantile_g3$quantile, "\n")
cat("Groupe 4 (APS, experts-half1):", quantile_g4$quantile, "\n")

```

```{r}

# Calcul du taux de couverture pour chaque groupe

coverage_g1 <- calculate_coverage(groupe1_test, quantile_g1$quantile, "one_minus_prob")
coverage_g2 <- calculate_coverage(groupe2_test, quantile_g2$quantile, "one_minus_prob")
coverage_g3 <- calculate_coverage(groupe3_test, quantile_g3$quantile, "sum_until_correct")
coverage_g4 <- calculate_coverage(groupe4_test, quantile_g4$quantile, "sum_until_correct")

cat("Taux de couverture:\n")
cat("Groupe 1:", round(coverage_g1$coverage_rate, 4), "(", coverage_g1$n_covered, "/", coverage_g1$n_test, ")\n")
cat("Groupe 2:", round(coverage_g2$coverage_rate, 4), "(", coverage_g2$n_covered, "/", coverage_g2$n_test, ")\n")
cat("Groupe 3:", round(coverage_g3$coverage_rate, 4), "(", coverage_g3$n_covered, "/", coverage_g3$n_test, ")\n")
cat("Groupe 4:", round(coverage_g4$coverage_rate, 4), "(", coverage_g4$n_covered, "/", coverage_g4$n_test, ")\n")

```

```{r}

# Calcul de la taille moyenne et médiane des ensembles de prédiction

cat("Tailles des ensembles de prédiction:\n")
cat("Groupe 1 - Moyenne:", round(coverage_g1$avg_size, 2), "- Médiane:", coverage_g1$median_size, "\n")
cat("Groupe 2 - Moyenne:", round(coverage_g2$avg_size, 2), "- Médiane:", coverage_g2$median_size, "\n")
cat("Groupe 3 - Moyenne:", round(coverage_g3$avg_size, 2), "- Médiane:", coverage_g3$median_size, "\n")
cat("Groupe 4 - Moyenne:", round(coverage_g4$avg_size, 2), "- Médiane:", coverage_g4$median_size, "\n")

```

```{r}

# Résumé des résultats
results_summary <- data.frame(
  Groupe = c("G1: 1-prob, non-exp->exp", "G2: 1-prob, exp->exp", "G3: APS, non-exp->exp", "G4: APS, exp->exp"),
  Quantile = c(quantile_g1$quantile, quantile_g2$quantile, quantile_g3$quantile, quantile_g4$quantile),
  Couverture = c(coverage_g1$coverage_rate, coverage_g2$coverage_rate, coverage_g3$coverage_rate, coverage_g4$coverage_rate),
  Taille_Moyenne = c(coverage_g1$avg_size, coverage_g2$avg_size, coverage_g3$avg_size, coverage_g4$avg_size),
  Taille_Mediane = c(coverage_g1$median_size, coverage_g2$median_size, coverage_g3$median_size, coverage_g4$median_size),
  N_Calibration = c(quantile_g1$n_calibration, quantile_g2$n_calibration, quantile_g3$n_calibration, quantile_g4$n_calibration),
  N_Test = c(coverage_g1$n_test, coverage_g2$n_test, coverage_g3$n_test, coverage_g4$n_test)
)

print(results_summary)

```

```




